{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVTa0iZMpijHtNITKocs88",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beingshub02/Deep-Learning-Summer-School-IIITDM/blob/main/25DLS455ASSIGNMENT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P-1. Data Preparation"
      ],
      "metadata": {
        "id": "R5xmkSXUWPT_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "p1eYdejJWKCN",
        "outputId": "8c3ce8c6-234d-4de9-bfaf-32bc9853dcab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (120, 4)\n",
            "X_test shape: (30, 4)\n",
            "y_train shape: (120, 3)\n",
            "y_test shape: (30, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)  # Reshape to column vector for encoding\n",
        "\n",
        "# One-hot encode the labels (compatible with newer sklearn)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Print shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P-2. Activation function"
      ],
      "metadata": {
        "id": "h3QeEkjDdOxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_activation_funcs(name):\n",
        "    if name == \"sigmoid\":\n",
        "        return lambda x: 1 / (1 + np.exp(-x)), lambda x: (x * (1 - x))  # Use output for derivative\n",
        "    elif name == \"relu\":\n",
        "        return lambda x: np.maximum(0, x), lambda x: (x > 0).astype(float)\n",
        "    elif name == \"tanh\":\n",
        "        return lambda x: np.tanh(x), lambda x: 1 - np.tanh(x)**2\n",
        "    elif name == \"leaky_relu\":\n",
        "        return lambda x: np.where(x > 0, x, 0.01 * x), lambda x: np.where(x > 0, 1, 0.01)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported activation\")\n",
        "\n",
        "# Test activations\n",
        "sample_input = np.array([[0, 1, -1]])\n",
        "\n",
        "sigmoid, _ = get_activation_funcs(\"sigmoid\")\n",
        "relu, _ = get_activation_funcs(\"relu\")\n",
        "\n",
        "print(\"Sigmoid output:\", sigmoid(sample_input))\n",
        "print(\"ReLU output:\", relu(sample_input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zTmVLFAgdPMR",
        "outputId": "1a40eca8-93a2-434d-d554-ea5da9fac951"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid output: [[0.5        0.73105858 0.26894142]]\n",
            "ReLU output: [[0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P-3. Train the MLP Model on Iris Data"
      ],
      "metadata": {
        "id": "q11b30KYdb2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train, X_test, y_test, activation_name, epochs=1000, lr=0.01, hidden_units=10):\n",
        "    act, act_deriv = get_activation_funcs(activation_name)\n",
        "\n",
        "    input_dim = X_train.shape[1]\n",
        "    output_dim = y_train.shape[1]\n",
        "\n",
        "    # Initialize weights\n",
        "    W1 = np.random.randn(input_dim, hidden_units) * 0.1\n",
        "    b1 = np.zeros((1, hidden_units))\n",
        "    W2 = np.random.randn(hidden_units, output_dim) * 0.1\n",
        "    b2 = np.zeros((1, output_dim))\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        z1 = X_train @ W1 + b1\n",
        "        a1 = act(z1)\n",
        "        z2 = a1 @ W2 + b2\n",
        "        out = 1 / (1 + np.exp(-z2))  # Output activation (sigmoid)\n",
        "\n",
        "        # Loss (MSE)\n",
        "        loss = np.mean((out - y_train) ** 2)\n",
        "        losses.append(loss)\n",
        "\n",
        "        # Backward pass\n",
        "        d_out = (out - y_train) * out * (1 - out)\n",
        "        dW2 = a1.T @ d_out\n",
        "        db2 = np.sum(d_out, axis=0, keepdims=True)\n",
        "\n",
        "        d_hidden = d_out @ W2.T * act_deriv(a1)\n",
        "        dW1 = X_train.T @ d_hidden\n",
        "        db1 = np.sum(d_hidden, axis=0, keepdims=True)\n",
        "\n",
        "        # Gradient descent\n",
        "        W1 -= lr * dW1\n",
        "        b1 -= lr * db1\n",
        "        W2 -= lr * dW2\n",
        "        b2 -= lr * db2\n",
        "\n",
        "    # Define predict function\n",
        "    def predict(X):\n",
        "        z1 = X @ W1 + b1\n",
        "        a1 = act(z1)\n",
        "        z2 = a1 @ W2 + b2\n",
        "        probs = 1 / (1 + np.exp(-z2))\n",
        "        return np.argmax(probs, axis=1)\n",
        "\n",
        "    y_pred = predict(X_test)\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "    accuracy = np.mean(y_pred == y_true)\n",
        "\n",
        "    return losses, accuracy, predict\n"
      ],
      "metadata": {
        "id": "L2ulbKV6dP_h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "P-4. Report Accuracy of Each Activation"
      ],
      "metadata": {
        "id": "qewhKkSNdjGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracies:\")\n",
        "print(accuracies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ujXTJsVldf_8",
        "outputId": "1b69905b-a56c-4ff4-844f-8cfbde10ac34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracies:\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P-5. Predict Class of a New Sample"
      ],
      "metadata": {
        "id": "H88F_HiCd6BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# P-5: Predict Class of a New Sample\n",
        "\n",
        "# New sample\n",
        "sample = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
        "\n",
        "# Use the same scaler used in P-1\n",
        "sample_scaled = scaler.transform(sample)\n",
        "\n",
        "# Use the trained ReLU model from P-3 (retrain if needed)\n",
        "_, _, model_predict_relu = train_model(X_train, y_train, X_test, y_test, activation_name=\"relu\")\n",
        "\n",
        "# Predict the class\n",
        "pred_class = model_predict_relu(sample_scaled)\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"\\nPredicted class index for sample [5.1, 3.5, 1.4, 0.2]:\", pred_class[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Hz5Z9MZKdpxn",
        "outputId": "91d15658-8252-4198-d92c-4a01cad1e84c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted class index for sample [5.1, 3.5, 1.4, 0.2]: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79L6ZJCUd8T4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}